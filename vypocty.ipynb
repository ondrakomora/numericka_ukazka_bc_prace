{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nahrání potřebných knihoven\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "V této buňce dochazí k načtení a předzpracování data. Proces probíhá následovně:\n",
    "1- Data se načtou do tabulky\n",
    "2- Předefinují se označení pro účel použití SVM\n",
    "3- Výběr datasetu, který se skládá ze 40% pozitivních a 60% negativních pozorování\n",
    "4- Promíchání datasetu\n",
    "5- Znormování prvků datasetu na interval [0,1]\n",
    "6- Rozdělení na trénovací a testovací množinu\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "digit_mnist_path = 'Digits-MNIST/train.csv'\n",
    "fashion_mnist_path = 'Fashion-MNIST/fashion-mnist_train.csv'\n",
    "\n",
    "pdf_digits = pd.read_csv(digit_mnist_path)\n",
    "pdf_fashion = pd.read_csv(fashion_mnist_path)\n",
    "\n",
    "pdf_digits['label'] = np.where(pdf_digits['label']==0,1,-1)\n",
    "pdf_fashion['label'] = np.where(pdf_fashion['label']==0,1,-1)\n",
    "\n",
    "test_size = 0.2\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def sample_and_shuffle(df):\n",
    "    df_p = df[df['label']==1]\n",
    "    df_n = df[df['label']==-1]\n",
    "    df_n_sample = df_n.sample(int(1.5*len(df_p.index)))\n",
    "\n",
    "    df_new = df_p.append(df_n_sample)\n",
    "    df_new_shuffled = shuffle(df_new)\n",
    "\n",
    "    return df_new_shuffled\n",
    "\n",
    "pdf_digits = sample_and_shuffle(pdf_digits)\n",
    "pdf_fashion = sample_and_shuffle(pdf_fashion)\n",
    "\n",
    "# pdf_digits = shuffle(pdf_digits)\n",
    "# pdf_fashion = shuffle(pdf_fashion)\n",
    "\n",
    "x_dig, y_dig =  pdf_digits[pdf_digits.columns[1:]].to_numpy()/255, pdf_digits['label'].to_numpy(),\n",
    "x_fash, y_fash = pdf_fashion[pdf_fashion.columns[1:]].to_numpy()/255, pdf_fashion['label'].to_numpy()\n",
    "\n",
    "x_dig_train, x_dig_test, y_dig_train, y_dig_test = train_test_split(x_dig, y_dig, test_size = test_size)\n",
    "x_fash_train, x_fash_test, y_fash_train, y_fash_test = train_test_split(x_fash, y_fash, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Třída model reprezentující algoritmy SSGD a PSSGD\n",
    "class Model:\n",
    "    params = np.array([])\n",
    "    reg = False\n",
    "    proxy = False\n",
    "\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    gamma = 0\n",
    "\n",
    "    def __init__(self, reg = False, proxy = False, alpha = 1, beta = 2, gamma = 0.1):\n",
    "        self.reg = reg\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if proxy:\n",
    "            self.reg = False\n",
    "            self.proxy = True\n",
    "\n",
    "    def initialize_params(self, data):\n",
    "        self.params = np.random.normal(0,1,len(data[0])+1)\n",
    "\n",
    "    # Posloupnost iteračních kroků 1/k\n",
    "    def learning_rates(self, k):\n",
    "        return 1/k\n",
    "    \n",
    "    # Explicitní řešení proximálního operátoru pro regularizaci MCP\n",
    "    def proximal_operator(self):\n",
    "        return np.where(\n",
    "            np.abs(self.params) >self.alpha*self.beta, \n",
    "            self.params, \n",
    "            np.where(\n",
    "                np.abs(self.params)<= self.alpha,\n",
    "                0,\n",
    "                np.sign(self.params)*(np.abs(self.params)-self.alpha)/(1-1/self.beta)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Subgradient ztrátové funkce SVM + L2 normy. V případě metody SSGD s regularizací přičítá subgradient funkce MCP.\n",
    "    def subgradient(self, data, target, batch_size):\n",
    "        sample_idxs = np.random.randint(np.shape(data)[0], size=batch_size)\n",
    "        x_batch, y_batch  = data[sample_idxs,:], target[sample_idxs]\n",
    "\n",
    "        loss_grad = np.zeros(1+len(data[0]))\n",
    "        for i in range(np.shape(x_batch)[0]):\n",
    "            x = x_batch[i]\n",
    "            y = y_batch[i]\n",
    "            hinge_loss = 1-y*(np.dot(self.params[1:], x)-self.params[0])\n",
    "            loss_grad += np.append(np.where(hinge_loss>0, y, 0), np.where(hinge_loss>0, -y*x, 0))\n",
    "        loss_grad = loss_grad/batch_size + self.gamma*self.params\n",
    "\n",
    "        if self.reg:\n",
    "            return loss_grad+self.gamma*self.regularization_subgradient()\n",
    "        else:\n",
    "            return loss_grad\n",
    "\n",
    "    # Počítá subgradient MCP\n",
    "    def regularization_subgradient(self):\n",
    "        return np.where(\n",
    "            np.abs(self.params) <= self.alpha*self.beta, \n",
    "            self.alpha*np.sign(self.params) - self.params/self.beta, \n",
    "            0\n",
    "        )\n",
    "\n",
    "    # Počítá MCP pro parametry modelu\n",
    "    def regularization_loss(self):\n",
    "        return np.where(\n",
    "            np.abs(self.params) <= self.alpha*self.beta,\n",
    "            self.alpha*np.abs(self.params) - np.square(self.params)/(2*self.beta),\n",
    "            self.alpha*self.beta**2/2\n",
    "        ).sum()\n",
    "\n",
    "    # Predikční funkce. Pozorováním přiřazuje kategorie.\n",
    "    def predict(self, data):\n",
    "        f = lambda x: np.dot(self.params[1:], x)- self.params[0]\n",
    "        predictions = np.apply_along_axis(f, 1, data)\n",
    "        predictions = np.where(predictions < 0, -1, 1)\n",
    "        return predictions\n",
    "\n",
    "    # Spočítá celkovou ztrátu modelu\n",
    "    def loss(self, data, target):\n",
    "        data_join = np.concatenate((data, target.reshape((-1,1))), 1)\n",
    "        hinge_loss = lambda x: np.maximum(0, 1-x[-1]*(np.dot(self.params[1:], x[:-1])-self.params[0]))\n",
    "        loss = np.apply_along_axis(hinge_loss, 1, data_join).mean()\n",
    "        if self.reg or self.proxy:\n",
    "            # return loss + self.gamma*self.regularization_loss()\n",
    "            return loss + np.linalg.norm(self.params)/2\n",
    "        else:\n",
    "            return loss + np.linalg.norm(self.params)/2\n",
    "\n",
    "    # Spočítá přesnost klasifikátoru na daném datasetu.\n",
    "    def accuracy(self, data, target):\n",
    "        predictions = self.predict(data)\n",
    "        acc = (predictions==target).mean()\n",
    "        return acc\n",
    "\n",
    "    # Spočítá řídkost parametrů. Z praktického hlediska se jako nulové parametry berou ty které jsou blízko nule.\n",
    "    def sparsity(self):\n",
    "        return (np.isclose(self.params,0, atol=1e-6)).mean()\n",
    "\n",
    "    # Metoda, která optimalizuje model na daných datech. Jsou k dispozici různé parametry optimalizace.\n",
    "    def train(self, data, target, n_iter = 2*10**5, batch_size = 1, verbose = True):\n",
    "        self.initialize_params(data)\n",
    "\n",
    "        for i in range(1, n_iter+1):\n",
    "            self.params  = self.params - self.learning_rates(i)*self.subgradient(data, target, batch_size)\n",
    "            if self.proxy:\n",
    "                self.params = self.proximal_operator()\n",
    "\n",
    "            if verbose and i%10000 == 0:\n",
    "                l= self.loss(data, target)\n",
    "                acc = self.accuracy(data, target)\n",
    "                spars = self.sparsity()\n",
    "                print(f'Iterace {i}: Ztráta: {l}, přesnost: {acc}, řídkost: {spars}')\n",
    "\n",
    "    # Sbírá data v průběhu trénování. Vrací data pro výkres grafů. Relativně pomalá metoda.\n",
    "    def training_data(self, data, target, n_iter = 10**5, batch_size = 10, interval = 10):\n",
    "        self.initialize_params(data)\n",
    "\n",
    "        loss_data, accuracy_data, sparsity_data = np.array([]), np.array([]), np.array([])\n",
    "        idxs =  np.array([])\n",
    "        for i in range(1, n_iter+1):\n",
    "            self.params  = self.params - self.learning_rates(i)*self.subgradient(data, target, batch_size)\n",
    "            if self.proxy:\n",
    "                self.params = self.proximal_operator()\n",
    "\n",
    "            if (i-1)%interval == 0 or (i-1)<=10:\n",
    "                l= self.loss(data, target)\n",
    "                acc = self.accuracy(data, target)\n",
    "                spars = self.sparsity()\n",
    "\n",
    "                idxs = np.append(idxs, i)\n",
    "                loss_data = np.append(loss_data, l)\n",
    "                accuracy_data = np.append(accuracy_data, acc)\n",
    "                sparsity_data = np.append(sparsity_data, spars)\n",
    "        return loss_data, accuracy_data, sparsity_data, idxs\n",
    "\n",
    "\n",
    "# Provede několik experimentů na daných modelech a datech.\n",
    "def perform_experiments(model, data_train, target_train, data_test, target_test, n_iter = 10**5, batch_size = 1, n_experiments = 10):\n",
    "    losses_train, accuracies_train = np.array([]), np.array([])\n",
    "    losses_test, accuracies_test = np.array([]), np.array([])\n",
    "    sparsities = np.array([])\n",
    "\n",
    "    for i in range(1, n_experiments+1):\n",
    "        np.random.seed(i)\n",
    "        model.train(data_train, target_train, n_iter, batch_size, False)\n",
    "\n",
    "        losses_train = np.append(losses_train, model.loss(data_train, target_train)) \n",
    "        accuracies_train = np.append(accuracies_train, model.accuracy(data_train, target_train))\n",
    "\n",
    "        losses_test = np.append(losses_test, model.loss(data_test, target_test)) \n",
    "        accuracies_test = np.append(accuracies_test, model.accuracy(data_test, target_test))\n",
    "\n",
    "        sparsities = np.append(sparsities, model.sparsity())\n",
    "\n",
    "        print(f'Experiment číslo {i} ukončen.')\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Sparsity\": sparsities,\n",
    "            \"Train loss\": losses_train,\n",
    "            \"Test loss\": losses_test,\n",
    "            \"Train accuracy\": accuracies_train,\n",
    "            \"Test accuracy\": accuracies_test\n",
    "        },\n",
    "        index = [f\"Experiment {i}\" for i in range(1, n_experiments+1)]\n",
    "    )\n",
    "\n",
    "# Metoda vytvořující grafy vývoje ztrátové funkce, přesnosti a řídkosti klasifikátoru.\n",
    "def plot_training_data(models, data, target, fig_names, n_iter = 10**5, batch_size = 10, interval = 10):\n",
    "    losses, accuracies, sparsities = [], [], []\n",
    "    idxs = []\n",
    "    for model in models:\n",
    "        x, y, z, w = model.training_data(data, target, n_iter, batch_size, interval)\n",
    "        losses.append(x), accuracies.append(y), sparsities.append(z)\n",
    "        idxs.append(w)\n",
    "    \n",
    "    plot_loss(losses, idxs[0], fig_names[0])\n",
    "    plot_accuracy(accuracies, idxs[1], fig_names[1])\n",
    "    plot_sparsity(sparsities, idxs[2], fig_names[2])\n",
    "\n",
    "# Tři metody vytvářející grafy pro různé charakteristiky trénování.\n",
    "def plot_loss(data, idxs, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    labels = ['SSGD', 'SSGD s regularizací', 'PSSGD']\n",
    "    for y, l in zip(data, labels):\n",
    "        ax.plot(idxs, y, label = l)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_tick_params(width=2.5)\n",
    "    ax.yaxis.set_tick_params(width=2.5)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Počet iterací\", fontsize=15)\n",
    "    plt.ylabel('Ztrátová funkce', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, format='pdf')\n",
    "\n",
    "def plot_accuracy(data, idxs, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    labels = ['SSGD', 'SSGD s regularizací', 'PSSGD']\n",
    "    for y, l in zip(data, labels):\n",
    "        ax.plot(idxs, y, label = l)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_tick_params(width=2.5)\n",
    "    ax.yaxis.set_tick_params(width=2.5)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Počet iterací\", fontsize=15)\n",
    "    plt.ylabel('Přesnost', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, format='pdf')\n",
    "\n",
    "def plot_sparsity(data, idxs, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    labels = ['SSGD', 'SSGD s regularizací', 'PSSGD']\n",
    "    for y, l in zip(data, labels):\n",
    "        ax.plot(idxs, y, label = l)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_tick_params(width=2.5)\n",
    "    ax.yaxis.set_tick_params(width=2.5)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Počet iterací\", fontsize=15)\n",
    "    plt.ylabel('Řídkost', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získání grafu pro průběh optimalizace na Digit MNIST.\n",
    "plot_training_data(\n",
    "    models= [Model(), Model(reg= True),  Model(proxy= True, alpha=0.1, beta=1.2)],\n",
    "    data= x_dig,\n",
    "    target= y_dig,\n",
    "    fig_names= ['plots/loss_plot_fig.pdf', 'plots/acc_plot_fig.pdf', 'plots/spars_plot_fig.pdf'],\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    interval= 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získání grafu pro průběh optimalizace na Fashion MNIST.\n",
    "plot_training_data(\n",
    "    models= [Model(), Model(reg= True),  Model(proxy= True, alpha=0.1, beta=1.2)],\n",
    "    data= x_fash,\n",
    "    target= y_fash,\n",
    "    fig_names= ['plots/loss_plot_fash.pdf', 'plots/acc_plot_fash.pdf', 'plots/spars_plot_fash.pdf'],\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    interval= 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Následující bloky dělají experimenty pro jednotlivé metody a datasety diskutované v bakalářské práci. Celkem jich je 6.\n",
    "digit_exp = perform_experiments(\n",
    "    model= Model(),\n",
    "    data_train= x_dig_train,\n",
    "    target_train= y_dig_train,\n",
    "    data_test= x_dig_test,\n",
    "    target_test= y_dig_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "digit_exp.to_csv('results/digit_exp.csv')\n",
    "print(digit_exp.mean())\n",
    "print(digit_exp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_reg_exp = perform_experiments(\n",
    "    model= Model(reg= True),\n",
    "    data_train= x_dig_train,\n",
    "    target_train= y_dig_train,\n",
    "    data_test= x_dig_test,\n",
    "    target_test= y_dig_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "digit_reg_exp.to_csv('results/digit_reg_exp.csv')\n",
    "print(digit_reg_exp.mean())\n",
    "print(digit_reg_exp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_exp = perform_experiments(\n",
    "    model= Model(),\n",
    "    data_train= x_fash_train,\n",
    "    target_train= y_fash_train,\n",
    "    data_test= x_fash_test,\n",
    "    target_test= y_fash_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "fashion_exp.to_csv('results/fashion_exp.csv')\n",
    "print(fashion_exp.mean())\n",
    "print(fashion_exp.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_reg_exp = perform_experiments(\n",
    "    model= Model(reg= True),\n",
    "    data_train= x_fash_train,\n",
    "    target_train= y_fash_train,\n",
    "    data_test= x_fash_test,\n",
    "    target_test= y_fash_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "fashion_reg_exp.to_csv('results/fashion_reg_exp.csv')\n",
    "print(fashion_reg_exp.mean())\n",
    "print(fashion_reg_exp.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_proxy_exp = perform_experiments(\n",
    "    model= Model(proxy= True, alpha=0.1, beta=1.1),\n",
    "    data_train= x_dig_train,\n",
    "    target_train= y_dig_train,\n",
    "    data_test= x_dig_test,\n",
    "    target_test= y_dig_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "digit_proxy_exp.to_csv('results/digit_proxy.csv')\n",
    "print(digit_proxy_exp.mean())\n",
    "print(digit_proxy_exp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_proxy_exp = perform_experiments(\n",
    "    model= Model(proxy= True, alpha=0.1, beta=1.1),\n",
    "    data_train= x_fash_train,\n",
    "    target_train= y_fash_train,\n",
    "    data_test= x_fash_test,\n",
    "    target_test= y_fash_test,\n",
    "    n_iter= 10**6,\n",
    "    batch_size= 25,\n",
    "    n_experiments= 1\n",
    ")\n",
    "fashion_proxy_exp.to_csv('results/fashion_proxy.csv')\n",
    "print(fashion_proxy_exp.mean())\n",
    "print(fashion_proxy_exp.std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
